{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data_path = \"../log-extractor/extracted_data_normalized.csv\"\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Preprocess data\n",
    "data = data.dropna()  # Drop rows with missing values\n",
    "\n",
    "# Extract necessary columns\n",
    "time, ip, url, normalized_url = data['Time'], data['IP'], data['URL'], data['Normalized_URL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encode URLs\n",
    "url_encoder = LabelEncoder()\n",
    "data['URL_encoded'] = url_encoder.fit_transform(data['URL'])\n",
    "data['Normalized_URL_encoded'] = url_encoder.fit_transform(data['Normalized_URL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Multi-Order Markov transition probabilities\n",
    "multi_order_transitions = defaultdict(lambda: defaultdict(int))\n",
    "order = 4\n",
    "\n",
    "for i in range(len(data) - order):\n",
    "    current_sequence = tuple(data['Normalized_URL_encoded'].iloc[i:i + order])\n",
    "    next_url = data['Normalized_URL_encoded'].iloc[i + order]\n",
    "    multi_order_transitions[current_sequence][next_url] += 1\n",
    "\n",
    "# Normalize probabilities\n",
    "multi_order_probs = {current: {next_url: count / sum(next_dict.values())\n",
    "                               for next_url, count in next_dict.items()}\n",
    "                     for current, next_dict in multi_order_transitions.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare sequential data for Neural Network\n",
    "sequences = []\n",
    "next_urls = []\n",
    "sequence_length = order\n",
    "\n",
    "for i in range(len(data) - sequence_length):\n",
    "    seq = data['Normalized_URL_encoded'].iloc[i:i + sequence_length].values\n",
    "    next_url = data['Normalized_URL_encoded'].iloc[i + sequence_length]\n",
    "    sequences.append(seq)\n",
    "    next_urls.append(next_url)\n",
    "\n",
    "sequences = np.array(sequences)\n",
    "next_urls = np.array(next_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(sequences, next_urls, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define batch processing generator with on-the-fly one-hot encoding\n",
    "def batch_generator(X, y, batch_size, num_classes):\n",
    "    num_samples = len(X)\n",
    "    while True:\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            end = min(offset + batch_size, num_samples)\n",
    "            X_batch = X[offset:end]\n",
    "            y_batch = tf.keras.utils.to_categorical(y[offset:end], num_classes=num_classes)\n",
    "            yield X_batch, y_batch\n",
    "\n",
    "# Get number of classes\n",
    "num_classes = len(url_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model with batch processing\n",
    "batch_size = 32\n",
    "train_gen = batch_generator(X_train, y_train, batch_size, num_classes)\n",
    "test_gen = batch_generator(X_test, y_test, batch_size, num_classes)\n",
    "\n",
    "steps_per_epoch = len(X_train) // batch_size\n",
    "validation_steps = len(X_test) // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Neural Network model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=num_classes, output_dim=50, input_length=sequence_length),\n",
    "    tf.keras.layers.LSTM(64, return_sequences=False),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_gen, epochs=10, steps_per_epoch=steps_per_epoch, validation_data=test_gen, validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict function combining Multi-Order Markov and Neural Network\n",
    "def predict_next_url(sequence):\n",
    "    # Use Multi-Order Markov model to get transition probabilities\n",
    "    markov_predictions = multi_order_probs.get(tuple(sequence), {})\n",
    "\n",
    "    # Use Neural Network for prediction\n",
    "    nn_prediction = model.predict(np.array([sequence]))[0]\n",
    "\n",
    "    # Combine Markov and Neural Network predictions\n",
    "    combined_probs = np.zeros(num_classes)\n",
    "    for url, prob in markov_predictions.items():\n",
    "        combined_probs[url] += prob\n",
    "    combined_probs += nn_prediction\n",
    "\n",
    "    # Handle unseen sequences\n",
    "    if not markov_predictions:\n",
    "        print(\"Warning: Sequence not found in training data. Using only Neural Network predictions.\")\n",
    "\n",
    "    # Return the URL with the highest combined probability\n",
    "    predicted_index = np.argmax(combined_probs)\n",
    "    return url_encoder.inverse_transform([predicted_index])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation metrics\n",
    "def evaluate_model():\n",
    "    correct = 0\n",
    "    top_3_correct = 0\n",
    "    top_5_correct = 0\n",
    "\n",
    "    for i in range(len(X_test)):\n",
    "        sequence = X_test[i]\n",
    "        true_label = y_test[i]\n",
    "\n",
    "        # Use Multi-Order Markov and Neural Network combined prediction\n",
    "        markov_predictions = multi_order_probs.get(tuple(sequence), {})\n",
    "        nn_prediction = model.predict(np.array([sequence]))[0]\n",
    "\n",
    "        combined_probs = np.zeros(num_classes)\n",
    "        for url, prob in markov_predictions.items():\n",
    "            combined_probs[url] += prob\n",
    "        combined_probs += nn_prediction\n",
    "\n",
    "        # Handle unseen sequences\n",
    "        if not markov_predictions:\n",
    "            print(f\"Warning: Sequence {sequence} not found in training data. Using only Neural Network predictions.\")\n",
    "\n",
    "        top_k_indices = np.argsort(combined_probs)[-5:][::-1]\n",
    "\n",
    "        if true_label in top_k_indices[:1]:\n",
    "            correct += 1\n",
    "        if true_label in top_k_indices[:3]:\n",
    "            top_3_correct += 1\n",
    "        if true_label in top_k_indices[:5]:\n",
    "            top_5_correct += 1\n",
    "\n",
    "    total = len(X_test)\n",
    "    accuracy = correct / total\n",
    "    top_3_accuracy = top_3_correct / total\n",
    "    top_5_accuracy = top_5_correct / total\n",
    "\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"Top-3 Accuracy: {top_3_accuracy * 100:.2f}%\")\n",
    "    print(f\"Top-5 Accuracy: {top_5_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example prediction\n",
    "example_sequence = X_test[0]\n",
    "predicted_url = predict_next_url(example_sequence)\n",
    "print(\"Predicted URL:\", predicted_url)\n",
    "\n",
    "# Evaluate model\n",
    "evaluate_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
